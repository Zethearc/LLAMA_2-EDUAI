{
  "model_path": "app/llm_models/7B/ggml-model-q4_0.bin",
  "init_prompt": "",
  "q_prompt": "### Instruction:",
  "a_prompt": "### Response:",
  "max_tokens": 512,
  "top_k": 100,
  "top_p": 0.95,
  "temperature": 0.7,
  "version": "0.0.1",
  "n_gpu_layers": 0,
  "n_batch": 64,
  "f16_kv": true,
  "n_threads": 4
}
